{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Lasso Regression Class\n",
    "\n",
    "The cell below contains a partial implementation of the `LassoRegression` class, which implements the lasso regression variant of linear regression. Complete this class by writing the `cost()` function. The rest of the code is complete. See the printed lab instructions for details on how the `cost()` function is calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegression:\n",
    "    \n",
    "    def __init__(self, X, y, alpha=0):\n",
    "        \n",
    "        def cost(beta):\n",
    "            \n",
    "            #\n",
    "            #  Write the code for the cost function.\n",
    "            #\n",
    "            \n",
    "            return cost\n",
    "        \n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.n_observations = len(y)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        beta_guess = np.zeros(self.X.shape[1] + 1)\n",
    "        min_results = minimize(cost, beta_guess)\n",
    "        self.coefficients = np.round(min_results.x,5)\n",
    "        \n",
    "        self.r_squared = self.score(self.X, self.y)\n",
    "       \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        return self.coefficients[0] + np.sum(self.coefficients[1:]*X, axis=1)\n",
    "\n",
    "    def score(self,X,y):\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        y_hat = self.predict(X)\n",
    "        sse = np.sum( (y - y_hat)**2 )\n",
    "        return 1 - sse / np.sum((y - np.mean(y))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Testing Data\n",
    "\n",
    "The cell below creates a simulated set of training data, and a simulated set of testing data. Run the cell as is. This will create the arrays `X_train`, `X_test`, `y_train`, and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(2560)\n",
    "\n",
    "X_train = np.random.uniform(0,10,1000).reshape(50,20)\n",
    "y_train = 3 + 1.3 * X_train[:,5] + 2.5 * X_train[:,13] + np.random.normal(0,4,50)\n",
    "\n",
    "X_test = np.random.uniform(0,10,400).reshape(20,20)\n",
    "y_test = 3 + 1.3 * X_test[:,5] + 2.5 * X_test[:,13] + np.random.normal(0,4,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models\n",
    "In the cell below, create two lasso regression models, as described below.\n",
    "* In the first model, set $\\alpha = 0$. In the second model, set $\\alpha = 10$.\n",
    "* Both models should be trained using `X_train` and `y_train`. \n",
    "* For each model, print the coefficients of the model. \n",
    "* For each model, print the training and testing accuracy of the model. Use the `score()` method.\n",
    "\n",
    "Some of the code is already provided for you below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create both models. \n",
    "#\n",
    "\n",
    "# Replace the blank lines in the print statements below. \n",
    "\n",
    "print('+-----------+')\n",
    "print('| alpha = 0 |')\n",
    "print('+-----------+')\n",
    "print('Coefficients', ________)\n",
    "\n",
    "print('\\nTraining r^2:', ________)\n",
    "print('Testing r^2:', ________)\n",
    "\n",
    "print('\\n')\n",
    "print('+------------+')\n",
    "print('| alpha = 10 |')\n",
    "print('+------------+')\n",
    "print('Coefficients', ________)\n",
    "\n",
    "print('\\nTraining r^2:', ________)\n",
    "print('Testing r^2:', ________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the Models\n",
    "\n",
    "In the cell below, answer the following questions:\n",
    "1. Which of the two models created above do you prefer, and why?\n",
    "2. What do you notice about the differences in the coefficients in the two models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Answer questions here.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Best Alpha\n",
    "\n",
    "Run the cell below. This will generate a plot of the training and testing r-squared values, as then depend on alpha. Then answer the question asked in the cell below the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_r2 = [] \n",
    "training_r2 = []\n",
    "for i in range(25):\n",
    "    mod = LassoRegression(X_train, y_train, i)\n",
    "    training_r2.append(mod.score(X_train, y_train))\n",
    "    testing_r2.append(mod.score(X_test, y_test))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.close()\n",
    "plt.figure(figsize=[8,4])\n",
    "plt.plot(training_r2, label='Training r^2')\n",
    "plt.plot(testing_r2, label='Testing r^2')\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('alpha')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you consider to be the optimal value for alpha? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Answer questions here.)**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will implement a multiclass classification model using several binary logistic regression classifiers. Running the cell below will load the `LogisticRegression` class into your workspace. Recall that this class contains the following methods:\n",
    "\n",
    "* `predict_proba(self, X)` \n",
    "* `predict(self, X, t=0.5)`\n",
    "\n",
    "It also contains methods called `summary()`, `score()`, and `confusion_matrix()`, but you will not need those for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LogisticRegression import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below contains a partial implementation of a class called `MultiClassLogisticRegresion`. This class implements our  multiclass classification algorithm. See the print lab instructions for details on how the algorithm works. \n",
    "\n",
    "Complete this class by finishing the constructor and the `predict()` method. They are explained in the lab instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassLogisticRegression:\n",
    "   \n",
    "    def __init__(self, X, y):\n",
    "                \n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.classes = np.unique(y)\n",
    "        self.models = []\n",
    "        \n",
    "        #\n",
    "        # Create one model for each class. Store in self.models. \n",
    "        #\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "\n",
    "        pred = np.zeros(X.shape[0])\n",
    "        prob = np.zeros(X.shape[0])\n",
    "                \n",
    "        #\n",
    "        #  Generate predictions.\n",
    "        #\n",
    "            \n",
    "        return pred\n",
    "            \n",
    "    def score(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        predictions = self.predict(X)\n",
    "        acc = np.sum(y == predictions) / len(y)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Model\n",
    "\n",
    "The two cells below create a synthetic dataset, which is then split into training and testing sets. A multiclass logistic model is then trained on the training data, and the training and testing accuracies are printed. \n",
    "\n",
    "Run both of these cells. You should get the following output:\n",
    "\n",
    "    Training Accuracy: 0.73125\n",
    "    Testing Accuracy: 0.705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, y2 = make_classification(n_samples = 1000, n_features = 6, n_informative = 6,\n",
    "                             n_redundant = 0, n_classes = 4, random_state=39)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.2, random_state=1)\n",
    "\n",
    "mc_mod = MultiClassLogisticRegression(X2_train, y2_train)\n",
    "\n",
    "print('Training Accuracy:', mc_mod.score(X2_train, y2_train))\n",
    "print('Testing Accuracy:', mc_mod.score(X2_test, y2_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
